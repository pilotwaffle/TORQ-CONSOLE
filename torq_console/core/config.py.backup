"""
TORQ CONSOLE Configuration Management.

Handles configuration loading, validation, and management for TORQ CONSOLE.
"""

import json
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
import logging
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class MCPServerConfig:
    """Configuration for an MCP server."""
    endpoint: str
    name: str
    enabled: bool = True
    auth_token: Optional[str] = None
    timeout: int = 30
    retry_count: int = 3


@dataclass
class AIModelConfig:
    """Configuration for AI models."""
    provider: str  # "openai", "anthropic", "ollama"
    model: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.7
    max_tokens: int = 4096


@dataclass
class VoiceConfig:
    """Configuration for voice features."""
    enabled: bool = False
    input_device: Optional[str] = None
    output_device: Optional[str] = None
    wake_word: str = "hey torq"
    language: str = "en-US"
    voice_model: str = "whisper-1"


@dataclass
class UIConfig:
    """Configuration for UI preferences."""
    theme: str = "dark"
    font_size: int = 14
    font_family: str = "Monaco"
    show_line_numbers: bool = True
    auto_save: bool = True
    auto_save_interval: int = 30  # seconds


@dataclass
class GitConfig:
    """Configuration for Git integration."""
    auto_commit: bool = False
    commit_message_template: str = "TORQ: {message}"
    diff_tool: str = "auto"
    merge_tool: str = "auto"


class TorqConfig:
    """
    Main configuration class for TORQ CONSOLE.

    Manages all configuration aspects including MCP servers, AI models,
    voice settings, UI preferences, and Git integration.
    """

    def __init__(self):
        self.config_dir = self.get_config_directory()
        self.config_file = self.config_dir / "config.json"

        # Configuration sections
        self.mcp_servers: List[MCPServerConfig] = []
        self.ai_models: List[AIModelConfig] = []
        self.voice: VoiceConfig = VoiceConfig()
        self.ui: UIConfig = UIConfig()
        self.git: GitConfig = GitConfig()

        # General settings
        self.version: str = "0.70.0"
        self.debug: bool = False
        self.log_level: str = "INFO"
        self.auto_update: bool = True

        # Runtime settings
        self.current_model: Optional[str] = None
        self.session_timeout: int = 3600  # seconds
        self.max_file_size: int = 10 * 1024 * 1024  # 10MB

        self.logger = logging.getLogger(__name__)

    @classmethod
    def get_config_directory(cls) -> Path:
        """Get the configuration directory path."""
        if os.name == 'nt':  # Windows
            config_dir = Path.home() / "AppData" / "Local" / "TORQ-CONSOLE"
        else:  # Unix-like systems
            config_dir = Path.home() / ".config" / "torq-console"

        config_dir.mkdir(parents=True, exist_ok=True)
        return config_dir

    @classmethod
    def get_default_path(cls) -> Path:
        """Get the default configuration file path."""
        return cls.get_config_directory() / "config.json"

    @classmethod
    def load(cls, config_path: Optional[Path] = None) -> 'TorqConfig':
        """Load configuration from file."""
        instance = cls()

        if config_path is None:
            config_path = instance.config_file

        if config_path.exists():
            try:
                instance._load_from_file(config_path)
                instance.logger.info(f"Configuration loaded from {config_path}")
            except Exception as e:
                instance.logger.error(f"Failed to load config from {config_path}: {e}")
                instance.logger.info("Using default configuration")
        else:
            instance.logger.info("Configuration file not found, using defaults")
            instance._set_defaults()

        return instance

    @classmethod
    def create_default(cls) -> 'TorqConfig':
        """Create a default configuration."""
        instance = cls()
        instance._set_defaults()
        return instance

    def _load_from_file(self, config_path: Path):
        """Load configuration from JSON file."""
        with open(config_path, 'r') as f:
            data = json.load(f)

        # Load MCP servers
        if 'mcp_servers' in data:
            self.mcp_servers = [
                MCPServerConfig(**server) for server in data['mcp_servers']
            ]

        # Load AI models
        if 'ai_models' in data:
            self.ai_models = [
                AIModelConfig(**model) for model in data['ai_models']
            ]

        # Load voice config
        if 'voice' in data:
            self.voice = VoiceConfig(**data['voice'])

        # Load UI config
        if 'ui' in data:
            self.ui = UIConfig(**data['ui'])

        # Load Git config
        if 'git' in data:
            self.git = GitConfig(**data['git'])

        # Load general settings
        self.version = data.get('version', self.version)
        self.debug = data.get('debug', self.debug)
        self.log_level = data.get('log_level', self.log_level)
        self.auto_update = data.get('auto_update', self.auto_update)
        self.current_model = data.get('current_model', self.current_model)
        self.session_timeout = data.get('session_timeout', self.session_timeout)
        self.max_file_size = data.get('max_file_size', self.max_file_size)

    def _set_defaults(self):
        """Set default configuration values."""
        # Default MCP servers (integrate with existing King Flowers infrastructure)
        self.mcp_servers = [
            MCPServerConfig(
                endpoint="http://localhost:3100",
                name="Hybrid MCP Server",
                enabled=True
            ),
            MCPServerConfig(
                endpoint="http://localhost:3101",
                name="N8N Proxy Server",
                enabled=True
            ),
            MCPServerConfig(
                endpoint="stdio://claude-memory-mcp",
                name="Claude Memory",
                enabled=True
            )
        ]

        # Default AI models
        self.ai_models = [
            AIModelConfig(
                provider="anthropic",
                model="claude-3-5-sonnet-20241022",
                api_key=os.getenv("ANTHROPIC_API_KEY")
            ),
            AIModelConfig(
                provider="openai",
                model="gpt-4",
                api_key=os.getenv("OPENAI_API_KEY")
            ),
            AIModelConfig(
                provider="ollama",
                model="codellama:7b",
                base_url="http://localhost:11434"
            )
        ]

        # Set current model
        if self.ai_models:
            self.current_model = f"{self.ai_models[0].provider}:{self.ai_models[0].model}"

    def save(self, config_path: Optional[Path] = None):
        """Save configuration to file."""
        if config_path is None:
            config_path = self.config_file

        try:
            # Ensure directory exists
            config_path.parent.mkdir(parents=True, exist_ok=True)

            # Prepare data for serialization
            data = {
                'version': self.version,
                'debug': self.debug,
                'log_level': self.log_level,
                'auto_update': self.auto_update,
                'current_model': self.current_model,
                'session_timeout': self.session_timeout,
                'max_file_size': self.max_file_size,
                'mcp_servers': [asdict(server) for server in self.mcp_servers],
                'ai_models': [asdict(model) for model in self.ai_models],
                'voice': asdict(self.voice),
                'ui': asdict(self.ui),
                'git': asdict(self.git),
                'last_updated': datetime.now().isoformat()
            }

            with open(config_path, 'w') as f:
                json.dump(data, f, indent=2)

            self.logger.info(f"Configuration saved to {config_path}")

        except Exception as e:
            self.logger.error(f"Failed to save config to {config_path}: {e}")
            raise

    def add_mcp_server(self, endpoint: str, name: Optional[str] = None) -> bool:
        """Add a new MCP server to the configuration."""
        try:
            # Check if server already exists
            for server in self.mcp_servers:
                if server.endpoint == endpoint:
                    self.logger.warning(f"MCP server {endpoint} already exists")
                    return False

            # Create new server config
            server_config = MCPServerConfig(
                endpoint=endpoint,
                name=name or f"MCP Server {len(self.mcp_servers) + 1}"
            )

            self.mcp_servers.append(server_config)
            self.logger.info(f"Added MCP server: {endpoint}")
            return True

        except Exception as e:
            self.logger.error(f"Failed to add MCP server {endpoint}: {e}")
            return False

    def remove_mcp_server(self, endpoint: str) -> bool:
        """Remove an MCP server from the configuration."""
        try:
            original_count = len(self.mcp_servers)
            self.mcp_servers = [
                server for server in self.mcp_servers
                if server.endpoint != endpoint
            ]

            if len(self.mcp_servers) < original_count:
                self.logger.info(f"Removed MCP server: {endpoint}")
                return True
            else:
                self.logger.warning(f"MCP server {endpoint} not found")
                return False

        except Exception as e:
            self.logger.error(f"Failed to remove MCP server {endpoint}: {e}")
            return False

    def get_mcp_server(self, endpoint: str) -> Optional[MCPServerConfig]:
        """Get MCP server configuration by endpoint."""
        for server in self.mcp_servers:
            if server.endpoint == endpoint:
                return server
        return None

    def add_ai_model(self, provider: str, model: str, **kwargs) -> bool:
        """Add a new AI model to the configuration."""
        try:
            # Check if model already exists
            for existing_model in self.ai_models:
                if existing_model.provider == provider and existing_model.model == model:
                    self.logger.warning(f"AI model {provider}:{model} already exists")
                    return False

            # Create new model config
            model_config = AIModelConfig(
                provider=provider,
                model=model,
                **kwargs
            )

            self.ai_models.append(model_config)
            self.logger.info(f"Added AI model: {provider}:{model}")
            return True

        except Exception as e:
            self.logger.error(f"Failed to add AI model {provider}:{model}: {e}")
            return False

    def get_current_ai_model(self) -> Optional[AIModelConfig]:
        """Get the currently configured AI model."""
        if not self.current_model:
            return None

        try:
            provider, model = self.current_model.split(':', 1)
            for ai_model in self.ai_models:
                if ai_model.provider == provider and ai_model.model == model:
                    return ai_model
        except ValueError:
            pass

        return None

    def set_current_model(self, provider: str, model: str) -> bool:
        """Set the current AI model."""
        for ai_model in self.ai_models:
            if ai_model.provider == provider and ai_model.model == model:
                self.current_model = f"{provider}:{model}"
                self.logger.info(f"Set current model to {self.current_model}")
                return True

        self.logger.error(f"AI model {provider}:{model} not found")
        return False

    def validate(self) -> List[str]:
        """Validate the configuration and return any errors."""
        errors = []

        # Validate MCP servers
        for i, server in enumerate(self.mcp_servers):
            if not server.endpoint:
                errors.append(f"MCP server {i}: endpoint is required")

        # Validate AI models
        for i, model in enumerate(self.ai_models):
            if not model.provider:
                errors.append(f"AI model {i}: provider is required")
            if not model.model:
                errors.append(f"AI model {i}: model is required")

            # Check for API keys where required
            if model.provider in ["openai", "anthropic"] and not model.api_key:
                errors.append(f"AI model {i}: API key required for {model.provider}")

        # Validate current model
        if self.current_model:
            current_model = self.get_current_ai_model()
            if not current_model:
                errors.append(f"Current model '{self.current_model}' not found in configured models")

        return errors

    def get_effective_config(self) -> Dict[str, Any]:
        """Get the effective configuration with environment variable overrides."""
        config = {
            'version': self.version,
            'debug': self.debug,
            'log_level': self.log_level,
            'auto_update': self.auto_update,
            'current_model': self.current_model,
            'session_timeout': self.session_timeout,
            'max_file_size': self.max_file_size,
            'mcp_servers': [asdict(server) for server in self.mcp_servers],
            'ai_models': [asdict(model) for model in self.ai_models],
            'voice': asdict(self.voice),
            'ui': asdict(self.ui),
            'git': asdict(self.git)
        }

        # Apply environment variable overrides
        if os.getenv('TORQ_DEBUG'):
            config['debug'] = os.getenv('TORQ_DEBUG').lower() == 'true'

        if os.getenv('TORQ_LOG_LEVEL'):
            config['log_level'] = os.getenv('TORQ_LOG_LEVEL')

        # Override API keys from environment
        for model in config['ai_models']:
            if model['provider'] == 'openai' and os.getenv('OPENAI_API_KEY'):
                model['api_key'] = os.getenv('OPENAI_API_KEY')
            elif model['provider'] == 'anthropic' and os.getenv('ANTHROPIC_API_KEY'):
                model['api_key'] = os.getenv('ANTHROPIC_API_KEY')

        return config

    def __str__(self) -> str:
        """String representation of the configuration."""
        return f"TorqConfig(version={self.version}, mcp_servers={len(self.mcp_servers)}, ai_models={len(self.ai_models)})"